{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Sonar Data\n",
    "\n",
    "Overview: Data set [description](http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)\n",
    "\n",
    "Predictors are attributes named `X1` through `X60`.  Response variable is `target`.\n",
    "\n",
    "Objective: develop feed-forward neural network to predict the `target`.\n",
    "\n",
    "Algorithm: [MLPClassifer](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=MLPClassifier)\n",
    "\n",
    "sklearn neural network [user guide](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# read in csv file\n",
    "#\n",
    "raw = pd.read_csv('./sonar.csv')\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1      X2      X3      X4      X5      X6      X7      X8      X9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      X10   ...       X52     X53     X54     X55     X56     X57     X58  \\\n",
       "0  0.2111   ...    0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872   ...    0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194   ...    0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264   ...    0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459   ...    0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      X59     X60  target  \n",
       "0  0.0090  0.0032       R  \n",
       "1  0.0052  0.0044       R  \n",
       "2  0.0095  0.0078       R  \n",
       "3  0.0040  0.0117       R  \n",
       "4  0.0107  0.0094       R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display sample\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.03080</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.2339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.03430</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.04405</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.4264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.4010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.09215</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.3823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X7</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.10695</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X8</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X9</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.15225</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.6828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X10</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>0.18240</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X11</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.236013</td>\n",
       "      <td>0.132705</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.129250</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.301650</td>\n",
       "      <td>0.7342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X12</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.250221</td>\n",
       "      <td>0.140072</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.24905</td>\n",
       "      <td>0.331250</td>\n",
       "      <td>0.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.273305</td>\n",
       "      <td>0.140962</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.166125</td>\n",
       "      <td>0.26395</td>\n",
       "      <td>0.351250</td>\n",
       "      <td>0.7131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.296568</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.175175</td>\n",
       "      <td>0.28110</td>\n",
       "      <td>0.386175</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X15</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.320201</td>\n",
       "      <td>0.205427</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.164625</td>\n",
       "      <td>0.28170</td>\n",
       "      <td>0.452925</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X16</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.378487</td>\n",
       "      <td>0.232650</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.30470</td>\n",
       "      <td>0.535725</td>\n",
       "      <td>0.9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X17</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.415983</td>\n",
       "      <td>0.263677</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.205850</td>\n",
       "      <td>0.30840</td>\n",
       "      <td>0.659425</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X18</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.452318</td>\n",
       "      <td>0.261529</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.242075</td>\n",
       "      <td>0.36830</td>\n",
       "      <td>0.679050</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X19</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.504812</td>\n",
       "      <td>0.257988</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.299075</td>\n",
       "      <td>0.43495</td>\n",
       "      <td>0.731400</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X20</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.563047</td>\n",
       "      <td>0.262653</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.350625</td>\n",
       "      <td>0.54250</td>\n",
       "      <td>0.809325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X21</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.609060</td>\n",
       "      <td>0.257818</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.399725</td>\n",
       "      <td>0.61770</td>\n",
       "      <td>0.816975</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X22</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.624275</td>\n",
       "      <td>0.255883</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.406925</td>\n",
       "      <td>0.66490</td>\n",
       "      <td>0.831975</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X23</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.646975</td>\n",
       "      <td>0.250175</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.450225</td>\n",
       "      <td>0.69970</td>\n",
       "      <td>0.848575</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X24</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.672654</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.540725</td>\n",
       "      <td>0.69850</td>\n",
       "      <td>0.872175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X25</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.675424</td>\n",
       "      <td>0.244926</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.525800</td>\n",
       "      <td>0.72110</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X26</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.699866</td>\n",
       "      <td>0.237228</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.544175</td>\n",
       "      <td>0.75450</td>\n",
       "      <td>0.893800</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X27</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.702155</td>\n",
       "      <td>0.245657</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.531900</td>\n",
       "      <td>0.74560</td>\n",
       "      <td>0.917100</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X28</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.694024</td>\n",
       "      <td>0.237189</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.534775</td>\n",
       "      <td>0.73190</td>\n",
       "      <td>0.900275</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X29</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.642074</td>\n",
       "      <td>0.240250</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.68080</td>\n",
       "      <td>0.852125</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X30</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.580928</td>\n",
       "      <td>0.220749</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.60715</td>\n",
       "      <td>0.735175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X31</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.504475</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.345550</td>\n",
       "      <td>0.49035</td>\n",
       "      <td>0.641950</td>\n",
       "      <td>0.9657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X32</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.439040</td>\n",
       "      <td>0.213237</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.42960</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.9306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X33</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.417220</td>\n",
       "      <td>0.206513</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.257875</td>\n",
       "      <td>0.39120</td>\n",
       "      <td>0.556125</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X34</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.403233</td>\n",
       "      <td>0.231242</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.217575</td>\n",
       "      <td>0.35105</td>\n",
       "      <td>0.596125</td>\n",
       "      <td>0.9647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X35</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.392571</td>\n",
       "      <td>0.259132</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.179375</td>\n",
       "      <td>0.31275</td>\n",
       "      <td>0.593350</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X36</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.384848</td>\n",
       "      <td>0.264121</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.154350</td>\n",
       "      <td>0.32115</td>\n",
       "      <td>0.556525</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X37</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.363807</td>\n",
       "      <td>0.239912</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.30630</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.9497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X38</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.339657</td>\n",
       "      <td>0.212973</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.174275</td>\n",
       "      <td>0.31270</td>\n",
       "      <td>0.440550</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X39</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>0.199075</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.173975</td>\n",
       "      <td>0.28350</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.9857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X40</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.311207</td>\n",
       "      <td>0.178662</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.186450</td>\n",
       "      <td>0.27805</td>\n",
       "      <td>0.424350</td>\n",
       "      <td>0.9297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X41</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.289252</td>\n",
       "      <td>0.171111</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.25950</td>\n",
       "      <td>0.387525</td>\n",
       "      <td>0.8995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X42</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.278293</td>\n",
       "      <td>0.168728</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.24510</td>\n",
       "      <td>0.384250</td>\n",
       "      <td>0.8246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X43</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.246542</td>\n",
       "      <td>0.138993</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.22255</td>\n",
       "      <td>0.324525</td>\n",
       "      <td>0.7733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X44</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.214075</td>\n",
       "      <td>0.133291</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.126875</td>\n",
       "      <td>0.17770</td>\n",
       "      <td>0.271750</td>\n",
       "      <td>0.7762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X45</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.197232</td>\n",
       "      <td>0.151628</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.094475</td>\n",
       "      <td>0.14800</td>\n",
       "      <td>0.231550</td>\n",
       "      <td>0.7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X46</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.160631</td>\n",
       "      <td>0.133938</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.068550</td>\n",
       "      <td>0.12135</td>\n",
       "      <td>0.200375</td>\n",
       "      <td>0.7292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X47</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.122453</td>\n",
       "      <td>0.086953</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.064250</td>\n",
       "      <td>0.10165</td>\n",
       "      <td>0.154425</td>\n",
       "      <td>0.5522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X48</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.091424</td>\n",
       "      <td>0.062417</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.045125</td>\n",
       "      <td>0.07810</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.3339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X49</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.051929</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.026350</td>\n",
       "      <td>0.04470</td>\n",
       "      <td>0.068525</td>\n",
       "      <td>0.1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X50</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.020424</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.01790</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X51</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.01390</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X52</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.01140</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.0709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X53</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.00955</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X54</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.00930</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X55</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X56</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.00685</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.0394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X57</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.00595</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.0355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X58</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.00580</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.0440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X59</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.00640</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X60</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.00530</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.0439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      mean       std     min       25%      50%       75%     max\n",
       "X1   208.0  0.029164  0.022991  0.0015  0.013350  0.02280  0.035550  0.1371\n",
       "X2   208.0  0.038437  0.032960  0.0006  0.016450  0.03080  0.047950  0.2339\n",
       "X3   208.0  0.043832  0.038428  0.0015  0.018950  0.03430  0.057950  0.3059\n",
       "X4   208.0  0.053892  0.046528  0.0058  0.024375  0.04405  0.064500  0.4264\n",
       "X5   208.0  0.075202  0.055552  0.0067  0.038050  0.06250  0.100275  0.4010\n",
       "X6   208.0  0.104570  0.059105  0.0102  0.067025  0.09215  0.134125  0.3823\n",
       "X7   208.0  0.121747  0.061788  0.0033  0.080900  0.10695  0.154000  0.3729\n",
       "X8   208.0  0.134799  0.085152  0.0055  0.080425  0.11210  0.169600  0.4590\n",
       "X9   208.0  0.178003  0.118387  0.0075  0.097025  0.15225  0.233425  0.6828\n",
       "X10  208.0  0.208259  0.134416  0.0113  0.111275  0.18240  0.268700  0.7106\n",
       "X11  208.0  0.236013  0.132705  0.0289  0.129250  0.22480  0.301650  0.7342\n",
       "X12  208.0  0.250221  0.140072  0.0236  0.133475  0.24905  0.331250  0.7060\n",
       "X13  208.0  0.273305  0.140962  0.0184  0.166125  0.26395  0.351250  0.7131\n",
       "X14  208.0  0.296568  0.164474  0.0273  0.175175  0.28110  0.386175  0.9970\n",
       "X15  208.0  0.320201  0.205427  0.0031  0.164625  0.28170  0.452925  1.0000\n",
       "X16  208.0  0.378487  0.232650  0.0162  0.196300  0.30470  0.535725  0.9988\n",
       "X17  208.0  0.415983  0.263677  0.0349  0.205850  0.30840  0.659425  1.0000\n",
       "X18  208.0  0.452318  0.261529  0.0375  0.242075  0.36830  0.679050  1.0000\n",
       "X19  208.0  0.504812  0.257988  0.0494  0.299075  0.43495  0.731400  1.0000\n",
       "X20  208.0  0.563047  0.262653  0.0656  0.350625  0.54250  0.809325  1.0000\n",
       "X21  208.0  0.609060  0.257818  0.0512  0.399725  0.61770  0.816975  1.0000\n",
       "X22  208.0  0.624275  0.255883  0.0219  0.406925  0.66490  0.831975  1.0000\n",
       "X23  208.0  0.646975  0.250175  0.0563  0.450225  0.69970  0.848575  1.0000\n",
       "X24  208.0  0.672654  0.239116  0.0239  0.540725  0.69850  0.872175  1.0000\n",
       "X25  208.0  0.675424  0.244926  0.0240  0.525800  0.72110  0.873725  1.0000\n",
       "X26  208.0  0.699866  0.237228  0.0921  0.544175  0.75450  0.893800  1.0000\n",
       "X27  208.0  0.702155  0.245657  0.0481  0.531900  0.74560  0.917100  1.0000\n",
       "X28  208.0  0.694024  0.237189  0.0284  0.534775  0.73190  0.900275  1.0000\n",
       "X29  208.0  0.642074  0.240250  0.0144  0.463700  0.68080  0.852125  1.0000\n",
       "X30  208.0  0.580928  0.220749  0.0613  0.411400  0.60715  0.735175  1.0000\n",
       "X31  208.0  0.504475  0.213992  0.0482  0.345550  0.49035  0.641950  0.9657\n",
       "X32  208.0  0.439040  0.213237  0.0404  0.281400  0.42960  0.580300  0.9306\n",
       "X33  208.0  0.417220  0.206513  0.0477  0.257875  0.39120  0.556125  1.0000\n",
       "X34  208.0  0.403233  0.231242  0.0212  0.217575  0.35105  0.596125  0.9647\n",
       "X35  208.0  0.392571  0.259132  0.0223  0.179375  0.31275  0.593350  1.0000\n",
       "X36  208.0  0.384848  0.264121  0.0080  0.154350  0.32115  0.556525  1.0000\n",
       "X37  208.0  0.363807  0.239912  0.0351  0.160100  0.30630  0.518900  0.9497\n",
       "X38  208.0  0.339657  0.212973  0.0383  0.174275  0.31270  0.440550  1.0000\n",
       "X39  208.0  0.325800  0.199075  0.0371  0.173975  0.28350  0.434900  0.9857\n",
       "X40  208.0  0.311207  0.178662  0.0117  0.186450  0.27805  0.424350  0.9297\n",
       "X41  208.0  0.289252  0.171111  0.0360  0.163100  0.25950  0.387525  0.8995\n",
       "X42  208.0  0.278293  0.168728  0.0056  0.158900  0.24510  0.384250  0.8246\n",
       "X43  208.0  0.246542  0.138993  0.0000  0.155200  0.22255  0.324525  0.7733\n",
       "X44  208.0  0.214075  0.133291  0.0000  0.126875  0.17770  0.271750  0.7762\n",
       "X45  208.0  0.197232  0.151628  0.0000  0.094475  0.14800  0.231550  0.7034\n",
       "X46  208.0  0.160631  0.133938  0.0000  0.068550  0.12135  0.200375  0.7292\n",
       "X47  208.0  0.122453  0.086953  0.0000  0.064250  0.10165  0.154425  0.5522\n",
       "X48  208.0  0.091424  0.062417  0.0000  0.045125  0.07810  0.120100  0.3339\n",
       "X49  208.0  0.051929  0.035954  0.0000  0.026350  0.04470  0.068525  0.1981\n",
       "X50  208.0  0.020424  0.013665  0.0000  0.011550  0.01790  0.025275  0.0825\n",
       "X51  208.0  0.016069  0.012008  0.0000  0.008425  0.01390  0.020825  0.1004\n",
       "X52  208.0  0.013420  0.009634  0.0008  0.007275  0.01140  0.016725  0.0709\n",
       "X53  208.0  0.010709  0.007060  0.0005  0.005075  0.00955  0.014900  0.0390\n",
       "X54  208.0  0.010941  0.007301  0.0010  0.005375  0.00930  0.014500  0.0352\n",
       "X55  208.0  0.009290  0.007088  0.0006  0.004150  0.00750  0.012100  0.0447\n",
       "X56  208.0  0.008222  0.005736  0.0004  0.004400  0.00685  0.010575  0.0394\n",
       "X57  208.0  0.007820  0.005785  0.0003  0.003700  0.00595  0.010425  0.0355\n",
       "X58  208.0  0.007949  0.006470  0.0003  0.003600  0.00580  0.010350  0.0440\n",
       "X59  208.0  0.007941  0.006181  0.0001  0.003675  0.00640  0.010325  0.0364\n",
       "X60  208.0  0.006507  0.005031  0.0006  0.003100  0.00530  0.008525  0.0439"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Descriptive statistics for predictors\n",
    "#\n",
    "raw.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Overview of target variable\n",
    "#\n",
    "raw.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    0.533654\n",
       "R    0.466346\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Calculate fraction of each response value\n",
    "#\n",
    "raw.target.value_counts()/raw.target.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 predictors: ['X1', 'X2', 'X3', 'X4', 'X5']\n",
      "\n",
      "last 5 predictors: ['X56', 'X57', 'X58', 'X59', 'X60']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# create dataframe containing only predictors X1 through X60\n",
    "#\n",
    "\n",
    "# generate predictor names\n",
    "predictors = ['X'+str(n) for n in range(1,61)]\n",
    "\n",
    "print('first 5 predictors:', predictors[:5])\n",
    "print('\\nlast 5 predictors:',predictors[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1      X2      X3      X4      X5      X6      X7      X8      X9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      X10   ...       X51     X52     X53     X54     X55     X56     X57  \\\n",
       "0  0.2111   ...    0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
       "1  0.2872   ...    0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "2  0.6194   ...    0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       "3  0.1264   ...    0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       "4  0.4459   ...    0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       "\n",
       "      X58     X59     X60  \n",
       "0  0.0084  0.0090  0.0032  \n",
       "1  0.0049  0.0052  0.0044  \n",
       "2  0.0164  0.0095  0.0078  \n",
       "3  0.0044  0.0040  0.0117  \n",
       "4  0.0048  0.0107  0.0094  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data frame\n",
    "raw_X = raw.loc[:,predictors]\n",
    "raw_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.533654\n",
       "0    0.466346\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# translate response attribute from 'M'/'R' to 1/0\n",
    "#\n",
    "raw_y = raw.target.map(dict(M=1,R=0))\n",
    "raw_y.value_counts()/raw_y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# 70%/30% split train/test data set\n",
    "# set random seed for repeatability\n",
    "#\n",
    "train_X, test_X, train_y, test_y = train_test_split(raw_X, raw_y, test_size=0.3, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training response attribute profile\n",
      " 1    0.531034\n",
      "0    0.468966\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('training response attribute profile\\n',train_y.value_counts()/train_y.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test response attribute profile\n",
      " 1    0.539683\n",
      "0    0.460317\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('test response attribute profile\\n', test_y.value_counts()/test_y.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# define neural network model architecture\n",
    "# one hidden layer with 10 nodes\n",
    "#\n",
    "nn = MLPClassifier(hidden_layer_sizes=(10,),max_iter=2000, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=31, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# fit model to training data\n",
    "#\n",
    "nn.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.84%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(100 * accuracy_score(test_y,nn.predict(test_X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Try standardizing the predictors\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=31, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# refit model with standardized predictors\n",
    "#\n",
    "nn = MLPClassifier(hidden_layer_sizes=(10,),max_iter=2000, random_state=31)\n",
    "\n",
    "# transform predictors into standardize form\n",
    "ss_train_X = ss.fit_transform(train_X)\n",
    "\n",
    "# train model\n",
    "nn.fit(ss.fit_transform(train_X),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.02%\n"
     ]
    }
   ],
   "source": [
    "# transform test data into standardized form\n",
    "ss_test_X = ss.transform(test_X)\n",
    "\n",
    "# check accuracy for standardized predictors\n",
    "print('accuracy: {:.2f}%'.format(100*accuracy_score(test_y,nn.predict(ss_test_X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test alternative network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# define network alternatives\n",
    "#\n",
    "hidden_layers = [\n",
    "    (10,), # 1 hidden layer, 10 nodes\n",
    "    (20,), # 1 hidden layer, 20 nodes\n",
    "    (50,), # 1 hidden layer, 50 nodes\n",
    "    (100,), # 1 hidden layer, 100 nodes\n",
    "    (25,25), # 2 hidden layers, 25 nodes/25 nodes\n",
    "    (40,40), # 2 hidden layers, 40 nodes/40 nodes\n",
    "    (50, 25), # 2 hidden layers, 50 nodes/25 nodes\n",
    "    (25,25,25), # 3 hidden layers, 25 nodes/ 25 nodes/ 25 nodes\n",
    "    (10,10,10), # 3 hidden layers, 10 nodes/ 10 nodes/ 10 nodes\n",
    "    (25,25,25,25) # 4 hidden layers, 25 nodes/ 25 nodes/ 25 nodes/ 25 nodes\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hidden layer: (10,)\n",
      "\taccuracy: 73.02%\n",
      "\n",
      "hidden layer: (20,)\n",
      "\taccuracy: 74.60%\n",
      "\n",
      "hidden layer: (50,)\n",
      "\taccuracy: 76.19%\n",
      "\n",
      "hidden layer: (100,)\n",
      "\taccuracy: 73.02%\n",
      "\n",
      "hidden layer: (25, 25)\n",
      "\taccuracy: 77.78%\n",
      "\n",
      "hidden layer: (40, 40)\n",
      "\taccuracy: 76.19%\n",
      "\n",
      "hidden layer: (50, 25)\n",
      "\taccuracy: 69.84%\n",
      "\n",
      "hidden layer: (25, 25, 25)\n",
      "\taccuracy: 76.19%\n",
      "\n",
      "hidden layer: (10, 10, 10)\n",
      "\taccuracy: 74.60%\n",
      "\n",
      "hidden layer: (25, 25, 25, 25)\n",
      "\taccuracy: 76.19%\n"
     ]
    }
   ],
   "source": [
    "# try each network alternatives\n",
    "results = []\n",
    "for hls in hidden_layers:\n",
    "    \n",
    "    # print hidden layer specification\n",
    "    print('\\nhidden layer: {}'.format(hls))\n",
    "    \n",
    "    # define neural network model\n",
    "    nn = MLPClassifier(hidden_layer_sizes=hls, max_iter=2000, random_state=31)\n",
    "    \n",
    "    # fit model\n",
    "    nn.fit(ss_train_X, train_y)\n",
    "    \n",
    "    # test model\n",
    "    test_accuracy = 100*accuracy_score(test_y,nn.predict(ss_test_X))\n",
    "    print('\\taccuracy: {:.2f}%'.format(test_accuracy))\n",
    "    \n",
    "    # keep track of test results\n",
    "    results.append(dict(hidden_layer=hls, test_accuracy=test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layer</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10,)</td>\n",
       "      <td>73.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(20,)</td>\n",
       "      <td>74.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(50,)</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(100,)</td>\n",
       "      <td>73.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(25, 25)</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(40, 40)</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(50, 25)</td>\n",
       "      <td>69.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(25, 25, 25)</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(10, 10, 10)</td>\n",
       "      <td>74.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(25, 25, 25, 25)</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hidden_layer  test_accuracy\n",
       "0             (10,)      73.015873\n",
       "1             (20,)      74.603175\n",
       "2             (50,)      76.190476\n",
       "3            (100,)      73.015873\n",
       "4          (25, 25)      77.777778\n",
       "5          (40, 40)      76.190476\n",
       "6          (50, 25)      69.841270\n",
       "7      (25, 25, 25)      76.190476\n",
       "8      (10, 10, 10)      74.603175\n",
       "9  (25, 25, 25, 25)      76.190476"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# convert test results into data frame\n",
    "#\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test Data Set Performance')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#\n",
    "# plot test data results\n",
    "#\n",
    "result_df.sort_values(by=['test_accuracy'],ascending=[True],inplace=True)\n",
    "ax = result_df.plot('hidden_layer','test_accuracy','barh',\n",
    "                    figsize=(9,7),\n",
    "                    legend=False)\n",
    "ax.set_xlabel('Accuracy Percent')\n",
    "ax.set_title('Test Data Set Performance',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
